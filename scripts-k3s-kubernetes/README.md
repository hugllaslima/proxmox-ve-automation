# ‚ò∏Ô∏è Automa√ß√£o de Cluster K3s para Proxmox VE

Este projeto oferece uma solu√ß√£o de automa√ß√£o completa para implantar um cluster K3s de alta disponibilidade, otimizado especificamente para ambientes Proxmox VE com recursos computacionais limitados. A su√≠te de scripts `bash` foi desenvolvida para ser leve e eficiente, permitindo que voc√™ crie e gerencie um ambiente Kubernetes robusto, aproveitando a flexibilidade da virtualiza√ß√£o sem a necessidade de hardware de ponta.

## ü§î Por que K3s? Uma An√°lise Comparativa

A escolha pelo **K3s** para este projeto foi estrat√©gica, visando um equil√≠brio ideal entre robustez, simplicidade e efici√™ncia de recursos, especialmente em um ambiente virtualizado como o Proxmox VE.

O K3s √© uma distribui√ß√£o Kubernetes leve e certificada pela **CNCF (Cloud Native Computing Foundation)**, desenvolvida pela Rancher. Ele √© projetado para cen√°rios com recursos limitados (como Edge, IoT e desenvolvimento) por ser empacotado em um √∫nico bin√°rio com menos de 100MB. Essa abordagem simplifica drasticamente a instala√ß√£o e o gerenciamento, mantendo total compatibilidade com as APIs do Kubernetes.

### K3s vs. K8s (Vanilla): Principais Diferen√ßas

Para entender a decis√£o, veja um comparativo direto entre as duas abordagens:

#### **K8s (Kubernetes "Vanilla" / `kubeadm`)**
- **Implementa√ß√£o Completa**: √â a vers√£o oficial e mais abrangente do Kubernetes, contendo todos os componentes tradicionais (API Server, Scheduler, etcd, etc.).
- **Padr√£o da Ind√∫stria**: Considerado o "padr√£o ouro" que define o ecossistema Kubernetes.
- **Curva de Aprendizagem e Recursos**: A instala√ß√£o e configura√ß√£o, mesmo com `kubeadm`, exigem mais recursos de hardware e um conhecimento mais aprofundado da arquitetura.

#### **K3s (Lightweight Kubernetes)**
- **Certificado e 100% Compat√≠vel**: Passa em todos os testes de conformidade da CNCF, garantindo que suas aplica√ß√µes funcionar√£o como esperado.
- **Otimizado para Leveza**:
    - Remove componentes legados e n√£o essenciais (como drivers de armazenamento *in-tree*).
    - Empacota todos os processos em um **√∫nico bin√°rio**, o que reduz o *overhead* e a superf√≠cie de ataque.
    - Utiliza `containerd` como runtime padr√£o, que √© mais leve e eficiente que o Docker para o contexto do Kubernetes.
- **Banco de Dados Flex√≠vel**:
    - Para n√≥s √∫nicos, pode usar **SQLite** embutido, tornando-o extremamente leve.
    - Para alta disponibilidade (HA), suporta bancos de dados externos como **PostgreSQL**, que √© a abordagem de alta disponibilidade utilizada neste projeto.

Em resumo, o K3s oferece a mesma funcionalidade e seguran√ßa do Kubernetes tradicional, mas com uma fra√ß√£o do custo operacional e da complexidade, tornando-o a escolha ideal para este ambiente.

O cluster resultante √© configurado com **tr√™s n√≥s de controle (control planes)** para garantir alta disponibilidade via Etcd embarcado, dois n√≥s de trabalho (workers), um servidor NFS para armazenamento persistente e, por fim, um servidor de gerenciamento.

## üìã Planejamento e Pr√©-requisitos de Rede

Antes de iniciar a instala√ß√£o, √© fundamental planejar sua rede e acessos para garantir que a automa√ß√£o funcione corretamente.

### 1. Reserva de IPs (MetalLB)
O cluster utilizar√° o **MetalLB** como Load Balancer para expor servi√ßos (como o Ingress Controller) na sua rede local.
- **Requisito**: Reserve uma faixa de IPs na sua rede (LAN) que **n√£o** esteja sendo distribu√≠da pelo seu servidor DHCP (roteador).
- **Quantidade**: Um pool pequeno √© suficiente. Recomenda-se reservar entre **5 a 10 IPs**.
- **Exemplo**: Se sua rede √© `192.168.10.0/24` e o DHCP vai at√© `.200`, voc√™ pode reservar de `192.168.10.240` a `192.168.10.250`.

### 2. Usu√°rio de Sistema
Os scripts assumem que voc√™ est√° utilizando um usu√°rio padr√£o (como **`ubuntu`**) em todas as VMs, com privil√©gios de `sudo` sem senha (ou que voc√™ conhe√ßa a senha).
- Este usu√°rio ser√° utilizado para conex√µes SSH entre a m√°quina de gerenciamento e os n√≥s do cluster.

## üèóÔ∏è Arquitetura de Refer√™ncia Utilizada no Proxmox VE

A arquitetura a seguir √© a configura√ß√£o de refer√™ncia testada para este projeto. Utiliza **3 Control Planes** para garantir quorum no Etcd.

| VM | Nome | SO | IP/CIDR | CPU | RAM | Volume |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| 1 | `k3s-control-plane-1` | Ubuntu 24.04 LTS | `192.168.10.20/24` | 2c | 4GB | 40GB |
| 2 | `k3s-control-plane-2` | Ubuntu 24.04 LTS | `192.168.10.21/24` | 2c | 4GB | 40GB |
| 3 | `k3s-control-plane-3` | Ubuntu 24.04 LTS | `192.168.10.22/24` | 2c | 4GB | 40GB |
| 4 | `k3s-worker-1` | Ubuntu 24.04 LTS | `192.168.10.23/24` | 4c | 6GB | 40GB |
| 5 | `k3s-worker-2` | Ubuntu 24.04 LTS | `192.168.10.24/24` | 4c | 6GB | 40GB |
| 6 | `k3s-storage-nfs` | Ubuntu 24.04 LTS | `192.168.10.25/24` | 2c | 4GB | 80GB |
| 7 | `k3s-management` | Ubuntu 24.04 LTS | `192.168.10.26/24` | 2c | 4GB | 30GB |

## ‚öôÔ∏è Como o Ambiente Funciona?

Esta se√ß√£o detalha o papel de cada componente e como eles interagem para formar um cluster funcional e resiliente. ao seu ambiente.

### Papel de Cada VM

- **`k3s-control-plane-1` e `k3s-control-plane-2` (N√≥s de Controle)**: Gerenciam o estado do cluster, distribui as cargas de trabalho entre os n√≥s de trabalho, agendam aplica√ß√µes e exp√µem a API do Kubernetes. A configura√ß√£o com dois n√≥s de controle e um banco de dados externo (PostgreSQL) garante a **alta disponibilidade (HA)** do *control plane*.
- **`k3s-worker-1` e `k3s-worker-2` (N√≥s de Trabalho)**: Executam as aplica√ß√µes e servi√ßos (em Pods) conforme orquestrado pelos n√≥s de controle.
- **`k3s-storage-nfs` (Armazenamento Persistente)**: Atua como um servidor NFS centralizado. Quando uma aplica√ß√£o precisa de dados persistentes (atrav√©s de um `PersistentVolumeClaim`), o K3s provisiona um diret√≥rio neste servidor. Isso garante que os dados sobrevivam a reinicializa√ß√µes de Pods e possam ser compartilhados entre eles.
- **`k3s-management` (Gerenciamento Centralizado)**: √â a VM de onde todos os comandos de gerenciamento (`kubectl`, `helm`) s√£o executados. Centralizar o gerenciamento em um n√≥ dedicado √© uma boa pr√°tica de seguran√ßa, pois isola as credenciais de acesso ao cluster.

### üîí Lidando com Redes Complexas e Conflitos de IP

Um desafio comum em ambientes de Datacenter/VPN √© o conflito entre a rede interna do Kubernetes e a rede f√≠sica.

**O Problema (Hijacking de Rede):**
Se voc√™ configurar a Rede de Pod do K3s (`--cluster-cidr`) com o mesmo intervalo da sua Rede F√≠sica/LAN, o Kubernetes ir√° "sequestrar" o tr√°fego da sua placa de rede, derrubando sua conex√£o SSH e tornando o servidor inacess√≠vel.

**A Solu√ß√£o deste Projeto:**
O script `install_k3s_control_plane.sh` agora distingue explicitamente estas duas redes:

1.  **Rede de PODS (`K3S_POD_CIDR`)**: O intervalo de IPs virtual para os cont√™ineres.
    -   *Padr√£o:* `10.42.0.0/16`
    -   **NUNCA** coloque o IP da sua rede f√≠sica aqui.
2.  **Rede LOCAL/LAN (`K3S_LAN_CIDR`)**: A sua rede f√≠sica real (ex: `192.168.10.0/24`).
    -   Usada apenas para liberar o acesso ao Banco de Dados (PostgreSQL) no firewall.

**Acesso Remoto via VPN:**
O script tamb√©m perguntar√° se voc√™ deseja adicionar "Redes de Administra√ß√£o". Se voc√™ acessa via VPN ou algum jump server (ex: `172.20.1.0/16`, `53.136.46.128/32`), adicione esse CIDR quando solicitado. O script configurar√° o Firewall (UFW) para permitir sua conex√£o sem alterar perigosamente as rotas do sistema.

### O que √© Armazenado em Cada N√≥?

- **N√≥s Control Plane**: A configura√ß√£o e o estado do cluster (objetos Kubernetes como `Deployments`, `Services`, etc.), que s√£o mantidos no banco de dados PostgreSQL.
- **N√≥s Worker**: As imagens de cont√™iner das aplica√ß√µes em execu√ß√£o e dados tempor√°rios.
- **N√≥ de Armazenamento (NFS)**: Todos os dados persistentes das aplica√ß√µes. √â o "disco r√≠gido" do cluster.
- **N√≥ de Gerenciamento**: Os arquivos de configura√ß√£o do `kubectl`, charts do Helm e manifestos YAML usados para gerenciar o cluster.

### Onde Encontrar os Logs?

A localiza√ß√£o dos logs depende do que voc√™ est√° tentando depurar:

- **Logs das Aplica√ß√µes (Pods)**
  - **M√©todo Principal**: Use o comando `kubectl` a partir da VM de gerenciamento. Este √© o m√©todo padr√£o para ver a sa√≠da das suas aplica√ß√µes.
    ```bash
    kubectl logs <nome-do-pod>
    ```


- **Logs da Infraestrutura (Servi√ßos K3s, NFS, etc.)**
  - **M√©todo Recomendado (`journalctl`)**: Para inspecionar os logs dos servi√ßos K3s nos n√≥s master e worker, o `journalctl` √© a ferramenta ideal, pois o K3s roda como um servi√ßo `systemd`.
    ```bash
    # Nos masters ou workers
    journalctl -u k3s
    ```
  - **Arquivos de Log Diretos**: Para inspe√ß√£o manual ou uso de ferramentas como `grep`, os arquivos de log brutos podem ser encontrados nos seguintes locais:
    - **N√≥s Master e Worker**: `/var/log/k3s/` (logs espec√≠ficos do K3s) e `/var/log/` (logs gerais do sistema).
    - **Servidor NFS**: `/var/log/` (para logs do servi√ßo NFS e outros logs do sistema).

## üìú Scripts Dispon√≠veis

### Scripts de Instala√ß√£o

- **`install_nfs_server.sh`**: Configura uma VM para atuar como um servidor NFS, que fornecer√° armazenamento persistente para o cluster.
- **`install_k3s_control_plane.sh`**: Instala e configura um n√≥ de controle (control plane) do K3s. Possui l√≥gica para diferenciar o primeiro control plane (que configura o banco de dados) do segundo, para criar um ambiente de alta disponibilidade (HA).
- **`install_k3s_worker.sh`**: Instala e configura um n√≥ de trabalho (worker) e o junta ao cluster K3s.
- **`install_k3s_management.sh`**: Deve ser executado em uma m√°quina de gerenciamento. Instala `kubectl`, `helm` e implanta addons essenciais: NFS Provisioner (para StorageClasses), MetalLB (para Load Balancers) e Nginx Ingress Controller.

### Scripts de Verifica√ß√£o

- **`verify_k3s_cluster_health.sh`**: Realiza um diagn√≥stico completo da sa√∫de do cluster. Verifica o status dos n√≥s, se os pods essenciais do sistema (`kube-system`) est√£o rodando e valida a consist√™ncia do cluster. Ideal para rodar logo ap√≥s a instala√ß√£o.

### Scripts de Manuten√ß√£o

- **`cluster_maintenance_tool.sh`**: Ferramenta interativa (menu) para facilitar tarefas rotineiras de manuten√ß√£o. Permite:
    - Excluir n√≥s antigos ou duplicados (limpeza de n√≥s "√≥rf√£os").
    - Drenar n√≥s para manuten√ß√£o (Drain).
    - For√ßar a exclus√£o de Pods travados em estado `Terminating`.
    - Gerenciar e excluir Namespaces inteiros.
    - Executar verifica√ß√µes de sa√∫de r√°pidas.

### Scripts de Limpeza

- **`cleanup_nfs_server.sh`**: Reverte a instala√ß√£o do servidor NFS.
- **`cleanup_k3s_control_plane.sh`**: Desinstala o K3s e limpa todas as configura√ß√µes de um n√≥ de controle.
- **`cleanup_k3s_worker.sh`**: Desinstala o agente K3s e limpa as configura√ß√µes de um n√≥ de trabalho.
- **`cleanup_k3s_management.sh`**: Remove todos os addons (NFS Provisioner, MetalLB, Nginx) e a configura√ß√£o local do `kubectl`.

## üìÇ Organiza√ß√£o de Diret√≥rios (Recomenda√ß√£o)

Para facilitar a organiza√ß√£o e a gest√£o futura do seu cluster, recomendamos criar um diret√≥rio padr√£o `/opt/k3s` em todos os servidores. Centralizar os scripts e arquivos de configura√ß√£o neste local ajuda a manter o ambiente limpo e padronizado.

```bash
# Exemplo de cria√ß√£o e organiza√ß√£o
sudo mkdir -p /opt/k3s
sudo chown $USER:$USER /opt/k3s
# Copie os scripts para este diret√≥rio
cp -r k3s_cluster_vars.sh /opt/k3s/
cd /opt/k3s
```

## üîë Pr√©-requisitos: Configura√ß√£o SSH

Para garantir a automa√ß√£o fluida (especialmente para a m√°quina de gerenciamento), √© altamente recomendado configurar a autentica√ß√£o via chaves SSH. Isso evita que os scripts parem para pedir senhas repetidamente.

**Onde executar:** Na m√°quina `k3s-management` (ou onde voc√™ rodar√° o script de gerenciamento).

1.  **Gere um par de chaves SSH (caso n√£o tenha):**
    ```bash
    ssh-keygen -t ed25519 -C "k3s-management"
    # Pressione ENTER para todas as perguntas para aceitar o padr√£o (sem passphrase).
    ```

2.  **Copie a chave p√∫blica para os n√≥s Control Plane:**
    O script de gerenciamento precisar√° acessar o `control-plane-1` (principalmente) para buscar configura√ß√µes.
    ```bash
    # Substitua 'usuario' pelo seu usu√°rio nos servidores (ex: ubuntu)
    ssh-copy-id usuario@192.168.10.20  # k3s-control-plane-1
    ssh-copy-id usuario@192.168.10.21  # k3s-control-plane-2 (Opcional, mas recomendado para redund√¢ncia)
    ```

Com isso, a m√°quina de gerenciamento ter√° acesso seguro e sem senha aos servidores, permitindo que o `install_k3s_management.sh` funcione de forma totalmente automatizada.

## üöÄ Ordem de Execu√ß√£o (Fluxo Automatizado)

Com a refatora√ß√£o dos scripts, o processo de implanta√ß√£o se tornou mais inteligente e seguro. O script `install_k3s_control_plane.sh` agora detecta automaticamente o seu papel (primeiro, segundo ou terceiro control plane), eliminando a necessidade de interven√ß√£o manual para gerenciar tokens.

Lembre-se de dar permiss√£o de execu√ß√£o (`chmod +x *.sh`) a todos os scripts antes de come√ßar.

1.  **VM de Armazenamento (`k3s-storage-nfs`)**
    - Execute o script para configurar o servidor NFS. Este passo continua o mesmo.
    ```bash
    sudo ./install_nfs_server.sh
    ```

2.  **Primeiro Control Plane (`k3s-control-plane-1`)**
    - Execute o script de instala√ß√£o do master.
    ```bash
    sudo ./install_k3s_control_plane.sh
    ```
    - Como o script n√£o encontrar√° um arquivo de configura√ß√£o, ele far√° uma s√©rie de perguntas para coletar os dados do cluster.
    - Ao final, ele gerar√° o arquivo `k3s_cluster_vars.sh` no diret√≥rio atual com todas as informa√ß√µes e instalar√° o K3s. O token do cluster ser√° **salvo automaticamente** neste arquivo.

3.  **Transfer√™ncia dos Scripts para o Segundo Control Plane**
    - Antes de configurar o segundo control plane, copie todo o diret√≥rio de scripts (que agora cont√©m o `k3s_cluster_vars.sh` com o token) para o `k3s-control-plane-2`.
    - Use o `scp` a partir do `k3s-control-plane-1`:
    ```bash
    # Exemplo: Copiando para a home do usu√°rio 'ubuntu' no control-plane-2
    scp -r ~/opt/k3s/k3s_cluster_vars.sh ubuntu@192.168.10.21:~/opt/k3s/
    ```
    - **Importante**: O script precisa do arquivo de configura√ß√£o gerado na etapa anterior para ingressar no cluster automaticamente.

4.  **Segundo Control Plane (`k3s-control-plane-2`)**
    - Execute o **mesmo script** de instala√ß√£o.
    ```bash
    sudo ./install_k3s_control_plane.sh
    ```
    - O script detectar√° o arquivo `k3s_cluster_vars.sh`, carregar√° todas as vari√°veis (incluindo o token) e configurar√° o segundo master em modo de alta disponibilidade (HA) **sem fazer nenhuma pergunta**.

5.  **N√≥s Workers (`k3s-worker-1`, `k3s-worker-2`)**
    - Assim como nos control planes, **copie o diret√≥rio de scripts** (contendo `k3s_cluster_vars.sh`) para cada worker.
    ```bash
    # Exemplo: Copiando do control-plane-1 para o worker-1
    scp -r ~/opt/k3s/k3s_cluster_vars.sh ubuntu@192.168.10.22:~/opt/k3s/
    ```
    - Execute o script de instala√ß√£o do worker:
    ```bash
    sudo ./install_k3s_worker.sh
    ```
    - **Instala√ß√£o Autom√°tica**: O script detectar√° o arquivo de configura√ß√£o e ingressar√° no cluster automaticamente, solicitando apenas uma confirma√ß√£o final para seguran√ßa.
    - **Fallback**: Se voc√™ n√£o copiar o arquivo de configura√ß√£o, o script perguntar√° manualmente o IP do Control Plane e o Token.

6.  **M√°quina de Gerenciamento (`k3s-management`)**
    - Ap√≥s o cluster estar no ar, execute o script de configura√ß√£o dos addons para instalar `kubectl`, `helm` e os componentes essenciais.
    - **Aten√ß√£o:** Execute este script **SEM sudo**, pois ele configura o ambiente para o seu usu√°rio atual.
    - **Pr√©-requisito**: Certifique-se de ter configurado as chaves SSH (passo "Pr√©-requisitos: Configura√ß√£o SSH" acima) antes de rodar este script.
    ```bash
    ./install_k3s_management.sh
    ```

## üîí Nota sobre Seguran√ßa e o `.gitignore`

Voc√™ notar√° um arquivo `.gitignore` neste diret√≥rio. Sua finalidade √© ser uma **medida de seguran√ßa preventiva para o seu ambiente de desenvolvimento local**.

Durante testes, √© poss√≠vel que voc√™ execute os scripts na sua pr√≥pria m√°quina, o que geraria o arquivo de configura√ß√£o `k3s_cluster_vars.sh` com dados sens√≠veis. O `.gitignore` est√° configurado para ignorar explicitamente este tipo de arquivo gerado localmente, garantindo que voc√™ nunca o envie acidentalmente para o seu reposit√≥rio p√∫blico no GitHub.

Ele garante que apenas os scripts principais do projeto sejam rastreados pelo Git, mantendo seus dados de configura√ß√£o seguros.

## üßπ Limpeza do Ambiente

Para desmontar o ambiente, utilize os scripts `cleanup_*.sh`. √â recomendado seguir a ordem inversa da instala√ß√£o:

1.  **Na m√°quina de gerenciamento**: Execute `sudo ./cleanup_k3s_addons.sh`.
2.  **Nos n√≥s workers**: Execute `sudo ./cleanup_k3s_worker.sh`.
3.  **Nos n√≥s control planes**: Execute `sudo ./cleanup_k3s_control_plane.sh`.
4.  **Na VM de armazenamento**: Execute `sudo ./cleanup_nfs_server.sh`.

Isso garantir√° que os servidores fiquem em um estado limpo e prontos para serem reutilizados.

## üíæ Estrat√©gias de Backup e Recupera√ß√£o

A alta disponibilidade (HA) protege contra falhas de hardware, mas n√£o contra erros humanos ou corrup√ß√£o catastr√≥fica de dados. Implementar uma rotina de backup √© obrigat√≥rio.

### 1. N√≠vel Proxmox VE (Infraestrutura)

O Proxmox Backup Server (PBS) ou os backups nativos do Proxmox s√£o a primeira linha de defesa.

-   **O que backupear**:
    -   Todas as VMs do Control Plane (`k3s-control-plane-*`).
    -   A VM de Storage NFS (`k3s-storage-nfs`).
-   **Frequ√™ncia Recomendada**: Di√°ria.
-   **Modo**: Utilize o modo "Snapshot" para evitar downtime das VMs.

### 2. N√≠vel Kubernetes/K3s (Aplica√ß√£o e Estado)

Para recupera√ß√µes granulares ou migra√ß√£o de cluster, voc√™ deve fazer backup do estado do K3s (Etcd).

-   **Backup do Etcd (Autom√°tico pelo K3s)**:
    -   O K3s, por padr√£o, j√° realiza snapshots do etcd a cada 12 horas e ret√©m os √∫ltimos 5.
    -   Localiza√ß√£o: `/var/lib/rancher/k3s/server/db/snapshots/`
-   **Backup Manual do Etcd**:
    -   Voc√™ pode for√ßar um backup a qualquer momento executando no control plane:
        ```bash
        sudo k3s etcd-snapshot save
        ```
-   **Recupera√ß√£o (Disaster Recovery)**:
    -   Em caso de perda total do cluster, voc√™ pode restaurar o estado usando um desses snapshots durante a instala√ß√£o de um novo n√≥ inicial.

### 3. N√≠vel de Armazenamento (Dados Persistentes)

-   Os dados das suas aplica√ß√µes vivem na VM `k3s-storage-nfs`.
-   Garanta que o diret√≥rio exportado (`/mnt/k3s-share-nfs` ou similar) esteja inclu√≠do nos backups da VM ou sincronizado com um local externo (ex: via `rsync` ou backup em nuvem).

## üè≠ Considera√ß√µes para Produ√ß√£o

Este ambiente K3s foi projetado para ser robusto e funcional, utilizando componentes reais de produ√ß√£o (MetalLB, Ingress Nginx, PostgreSQL externo). Ele √© adequado para ambientes de desenvolvimento, homelab avan√ßado e pequenas/m√©dias empresas.

No entanto, para ambientes de **Produ√ß√£o Cr√≠tica** ("Enterprise"), esteja ciente dos seguintes **Pontos de Aten√ß√£o**:

1.  **Banco de Dados (SPOF)**:
    - O PostgreSQL est√° instalado no `k3s-control-plane-1`. Se esta VM for perdida sem backup, o cluster perder√° seu estado, mesmo com um segundo control-plane ativo.
    - **Recomenda√ß√£o**: Mantenha backups di√°rios/hor√°rios desta VM ou externalize o banco de dados.

2.  **Storage NFS (SPOF)**:
    - O armazenamento persistente depende de uma √∫nica VM (`k3s-storage-nfs`). Falhas nela afetar√£o todos os Pods com volumes persistentes.
    - **Recomenda√ß√£o**: Utilize RAID no host Proxmox e fa√ßa snapshots regulares da VM de NFS.

Mantendo uma rotina de backups adequada, este cluster entregar√° alta disponibilidade para a API e efici√™ncia de recursos superior a um cluster Kubernetes tradicional.

---

## üë®‚Äçüíª Autor

**Hugllas R S Lima**

- **GitHub:** [@hugllaslima](https://github.com/hugllaslima)
- **LinkedIn:** [hugllas-lima](https://www.linkedin.com/in/hugllas-lima/)


